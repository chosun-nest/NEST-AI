from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from urllib.parse import urljoin
import requests
import time
# import os
# from dotenv import load_dotenv

# load_dotenv()
# SPRING_SERVER_BASE_URL = os.getenv("SPRING_SERVER_BASE_URL", "http://localhost:6030")


app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í¬ë¡¤ë§ ëŒ€ìƒ URL (ì¹´í…Œê³ ë¦¬ë³„)
# SWì¤‘ì‹¬ëŒ€í•™ì‚¬ì—…ë‹¨ êµ¬ì¡°: ë³„ë„ ë…ë¦½ì 
# ì¼ë°˜ê³µì§€, ì¥í•™ê³µì§€ êµ¬ì¡°: ê°™ìŒ
# ì¥í•™ê³µì§€: ë§ˆê°ì¼ ì¶”ê°€
# ë‚˜ë¨¸ì§€ êµ¬ì¡°: ê°™ìŒ
CATEGORIES = {
    "ì¼ë°˜ê³µì§€": "https://www3.chosun.ac.kr/chosun/217/subview.do",
    "í•™ì‚¬ê³µì§€": "https://www4.chosun.ac.kr/acguide/9326/subview.do?layout=unknown",
    "ì¥í•™ê³µì§€": "https://www3.chosun.ac.kr/scho/2138/subview.do",
    "SWì¤‘ì‹¬ëŒ€í•™ì‚¬ì—…ë‹¨": "https://sw.chosun.ac.kr/main/menu?gc=605XOAS",
    "ITìœµí•©ëŒ€í•™": "https://eie.chosun.ac.kr/eie/5563/subview.do",
    "ì»´í“¨í„°ê³µí•™ì „ê³µ": "https://eie.chosun.ac.kr/ce/5670/subview.do",
    "ì •ë³´í†µì‹ ê³µí•™ì „ê³µ": "https://eie.chosun.ac.kr/ice/7953/subview.do",
    "ì¸ê³µì§€ëŠ¥ê³µí•™ì „ê³µ": "https://eie.chosun.ac.kr/aie/7977/subview.do",
    "ëª¨ë¹Œë¦¬í‹°SWì „ê³µ": "https://mobility.chosun.ac.kr/mobility/12563/subview.do"

}

# ê¸°ë³¸ URL ì¶”ì¶œ í•¨ìˆ˜
def get_base_url(full_url: str):
    parts = full_url.split("/", 3)
    return f"{parts[0]}//{parts[2]}"

@app.get("/crawl/{category}")
def crawl_notices(category: str):
    url = CATEGORIES.get(category)
    if not url:
        return {"error": f"Invalid category '{category}'"}

    # BASE_URL ì¶”ì¶œ
    BASE_URL = get_base_url(url)

    # Selenium ì˜µì…˜ ì„¤ì •
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("user-agent=Mozilla/5.0")

    # ChromeDriver ì„¤ì¹˜ ë° ë¡œë“œ
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    driver.get(url)

    notices = []
    MAX_PAGE = 30  # ê³µì§€ 300ê°œ ì´ìƒì´ë©´ 30~50 ì„¤ì •

    # ê³µì§€ì‚¬í•­ í–‰ ì„ íƒ
    for page in range(1, MAX_PAGE + 1):
        try:
            if category == "SWì¤‘ì‹¬ëŒ€í•™ì‚¬ì—…ë‹¨":
                driver.get(f"{url}&do=list&page={page}")
            else:
                driver.get(url)
                time.sleep(0.5)
                driver.execute_script(f"page_link('{page}')")

            time.sleep(1.2)
            soup = BeautifulSoup(driver.page_source, "html.parser")

            if category == "SWì¤‘ì‹¬ëŒ€í•™ì‚¬ì—…ë‹¨":
                rows = soup.select("table.board_list tbody tr")
                print(f"ğŸ”¥ SWì¤‘ì‹¬ rows: {len(rows)}")

                for row in rows:
                    try:
                        if "notice" in row.get("class", []):
                            continue

                        cols = row.find_all("td")
                        if len(cols) < 5:
                            continue

                        number = cols[0].text.strip()
                        title_tag = cols[1].select_one("a > p")
                        title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"

                        a_tag = cols[1].select_one("a")
                        link = a_tag["href"] if a_tag and a_tag.has_attr("href") else ""
                        if not link.startswith("http"):
                            link = urljoin(BASE_URL, link)

                        writer = cols[2].text.strip()
                        date = cols[3].text.strip()
                        views = cols[4].text.replace("ì¡°íšŒ :", "").strip()

                        if not date.startswith("2025"):
                            continue

                        notices.append({
                            "category": category,
                            "number": number,
                            "title": title,
                            "writer": writer,
                            "date": date,
                            "views": views,
                            "link": link
                        })

                    except Exception as e:
                        print(f"âŒ SWê³µì§€ row íŒŒì‹± ì‹¤íŒ¨: {e}")

                continue

            # ê·¸ ì™¸ ì¼ë°˜/ì¥í•™/í•™ê³¼ ê³µì§€
            rows = soup.select("table tbody tr")
            for row in rows:
                cols = row.find_all("td")
                if len(cols) < 5:
                    continue

                number_text = cols[0].text.strip()
                if number_text in ["", "ì¼ë°˜ê³µì§€"]:
                    continue

                number = number_text
                title = cols[1].text.strip()
                writer = cols[2].text.strip()

                if category == "ì¥í•™ê³µì§€":
                    date_divs = cols[3].find_all("div", class_="date_fl")
                    date = date_divs[0].text.strip() if date_divs else cols[3].text.strip()
                else:
                    date = cols[3].text.strip()

                views = cols[4].text.strip().replace(",", "")
                link_tag = cols[1].select_one("a")
                href = link_tag["href"] if link_tag else ""
                link = urljoin(BASE_URL, href)

                if not date.startswith("2025"):
                    continue

                notice = {
                    "category": category,
                    "number": number,
                    "title": title,
                    "writer": writer,
                    "date": date,
                    "views": views,
                    "link": link
                }

                if category == "ì¥í•™ê³µì§€" and len(date_divs) > 1:
                    deadline = date_divs[1].text.strip()
                    notice["deadline"] = deadline

                notices.append(notice)
        except Exception as e:
            print(f"âŒ page {page} error: {e}")
            continue
        
    driver.quit()

     #  í¬ë¡¤ë§ ê²°ê³¼ í™•ì¸
    print(f"ğŸ“¦ ì „ì†¡í•  ê³µì§€ ê°œìˆ˜: {len(notices)}")
    if not notices:
        print("ğŸš¨ í¬ë¡¤ë§ëœ ê³µì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")


    # Spring APIë¡œ ì „ì†¡
    try:
        api_url = f"http://49.246.71.236:6030/api/v1/notices/{category}"
        res = requests.post(api_url, json={"notices": notices})
        print(f"âœ… ë“±ë¡ ì‹œë„ ìƒíƒœ ì½”ë“œ: {res.status_code}")
        print(f"âœ… ì‘ë‹µ ë³¸ë¬¸: {res.text}")  # ì—¬ê¸°ì„œ JSONì´ ì•ˆ ë‚˜ì˜¤ë©´ ë¬¸ì œ!
        print(f"âœ… ì‘ë‹µ Content-Type: {res.headers.get('Content-Type')}")
    
        # ì´ ì¤„ì€ try ë°–ìœ¼ë¡œ ë¹¼ëŠ” ê²Œ ì¢‹ìŒ
        res_json = res.json()  # ì—¬ê¸°ì„œ JSON ì•„ë‹ˆë¼ì„œ ì˜ˆì™¸ ë°œìƒ ì¤‘
        print(f"âœ… ë“±ë¡ ì„±ê³µ ì‘ë‹µ: {res_json}")
    except Exception as e:
        print(f"âŒ ë“±ë¡ ì‹¤íŒ¨: {e}")


    return {"message": f"{len(notices)}ê°œ {category} ë“±ë¡ ì™„ë£Œ", "notices": notices}

# FastAPI ì„œë²„ ì‹¤í–‰ì„ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)